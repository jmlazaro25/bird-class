{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f0452d2-fc72-42c2-b525-ed3dd446e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree, copy\n",
    "from glob import glob\n",
    "from random import sample\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "DATA_MOD_DIR = DATA_DIR + '_mod'\n",
    "\n",
    "def get_classes():\n",
    "    return {\n",
    "                i: os.path.split(name)[-1] for i, name in\n",
    "                enumerate(sorted(glob(os.path.join(DATA_DIR, 'test', '*'))))\n",
    "           }\n",
    "\n",
    "def make_data_mod_uni(files_per_class, refresh):\n",
    "    if os.path.exists(DATA_MOD_DIR) and not refresh:\n",
    "        return\n",
    "\n",
    "    if os.path.exists(DATA_MOD_DIR):\n",
    "        rmtree(DATA_MOD_DIR)\n",
    "    \n",
    "    for name in get_classes().values():\n",
    "        os.makedirs(os.path.join(DATA_MOD_DIR, name))\n",
    "        files_to_copy = glob(os.path.join(DATA_DIR, 'train', name, '*'))\n",
    "        files_to_copy = sample(files_to_copy, min(files_per_class, len(files_to_copy)))\n",
    "        for f in files_to_copy:\n",
    "            copy(f, os.path.join(DATA_MOD_DIR, name))\n",
    "    return            \n",
    "\n",
    "make_data_mod_uni(25, refresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9afb886-4a0a-4598-ac69-b3cb24d17a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 17:03:48.979639: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-23 17:03:49.225600: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-23 17:03:49.228702: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-23 17:03:50.336736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84635 files belonging to 525 classes.\n",
      "Using 42318 files for training.\n",
      "Found 2626 files belonging to 525 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "RAW_IMAGE_HEIGHT = 224\n",
    "RAW_IMAGE_WIDTH = 224\n",
    "RAW_IMAGE_CHANNELS = 3\n",
    "\n",
    "batch_size = 256\n",
    "dataset_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR, 'train'),\n",
    "    batch_size=batch_size,\n",
    "    image_size=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH),\n",
    "    crop_to_aspect_ratio=True,\n",
    "    seed=1,\n",
    "    validation_split=0.5,\n",
    "    subset='training'    \n",
    ")\n",
    "dataset_valid = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR, 'valid'),\n",
    "    #label_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH),\n",
    "    crop_to_aspect_ratio=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4f442-719e-4b88-a940-1ff42d199f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 6.5764 - accuracy: 0.0030 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 2197s 13s/step - loss: 6.5764 - accuracy: 0.0030 - val_loss: 6.2371 - val_accuracy: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 6.2381 - accuracy: 0.0040 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1956s 12s/step - loss: 6.2381 - accuracy: 0.0040 - val_loss: 6.1745 - val_accuracy: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 6.1599 - accuracy: 0.0090 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1969s 12s/step - loss: 6.1599 - accuracy: 0.0090 - val_loss: 6.0056 - val_accuracy: 0.0255 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 6.0157 - accuracy: 0.0166 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1985s 12s/step - loss: 6.0157 - accuracy: 0.0166 - val_loss: 5.7300 - val_accuracy: 0.0609 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 5.7944 - accuracy: 0.0302 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 2024s 12s/step - loss: 5.7944 - accuracy: 0.0302 - val_loss: 5.3251 - val_accuracy: 0.1112 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 5.4940 - accuracy: 0.0478 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1994s 12s/step - loss: 5.4940 - accuracy: 0.0478 - val_loss: 4.7610 - val_accuracy: 0.1923 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 5.1397 - accuracy: 0.0719 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1999s 12s/step - loss: 5.1397 - accuracy: 0.0719 - val_loss: 4.1685 - val_accuracy: 0.2708 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.7886 - accuracy: 0.0934 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 2022s 12s/step - loss: 4.7886 - accuracy: 0.0934 - val_loss: 3.6557 - val_accuracy: 0.3641 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.5094 - accuracy: 0.1138 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1985s 12s/step - loss: 4.5094 - accuracy: 0.1138 - val_loss: 3.2437 - val_accuracy: 0.4532 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.2464 - accuracy: 0.1401 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 2044s 12s/step - loss: 4.2464 - accuracy: 0.1401 - val_loss: 2.8776 - val_accuracy: 0.5179 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.0381 - accuracy: 0.1584 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 2026s 12s/step - loss: 4.0381 - accuracy: 0.1584 - val_loss: 2.5624 - val_accuracy: 0.5834 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.8584 - accuracy: 0.1799 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 2062s 12s/step - loss: 3.8584 - accuracy: 0.1799 - val_loss: 2.3240 - val_accuracy: 0.6318 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.6706 - accuracy: 0.2026 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1987s 12s/step - loss: 3.6706 - accuracy: 0.2026 - val_loss: 2.1076 - val_accuracy: 0.6649 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.5283 - accuracy: 0.2185 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1808s 11s/step - loss: 3.5283 - accuracy: 0.2185 - val_loss: 1.9330 - val_accuracy: 0.6915 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.4056 - accuracy: 0.2374 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1807s 11s/step - loss: 3.4056 - accuracy: 0.2374 - val_loss: 1.7772 - val_accuracy: 0.7178 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.2652 - accuracy: 0.2582INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1809s 11s/step - loss: 3.2652 - accuracy: 0.2582 - val_loss: 1.6447 - val_accuracy: 0.7414 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.1602 - accuracy: 0.2713 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1804s 11s/step - loss: 3.1602 - accuracy: 0.2713 - val_loss: 1.5486 - val_accuracy: 0.7540 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.0640 - accuracy: 0.2884 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1836s 11s/step - loss: 3.0640 - accuracy: 0.2884 - val_loss: 1.4258 - val_accuracy: 0.7711 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.9615 - accuracy: 0.3036INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1795s 11s/step - loss: 2.9615 - accuracy: 0.3036 - val_loss: 1.3481 - val_accuracy: 0.7826 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.8996 - accuracy: 0.3148 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1867s 11s/step - loss: 2.8996 - accuracy: 0.3148 - val_loss: 1.2790 - val_accuracy: 0.7947 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.7904 - accuracy: 0.3354 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1847s 11s/step - loss: 2.7904 - accuracy: 0.3354 - val_loss: 1.1799 - val_accuracy: 0.8039 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.7214 - accuracy: 0.3453 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1871s 11s/step - loss: 2.7214 - accuracy: 0.3453 - val_loss: 1.1429 - val_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.6570 - accuracy: 0.3571 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1803s 11s/step - loss: 2.6570 - accuracy: 0.3571 - val_loss: 1.0840 - val_accuracy: 0.8134 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.5756 - accuracy: 0.3704 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1815s 11s/step - loss: 2.5756 - accuracy: 0.3704 - val_loss: 1.0239 - val_accuracy: 0.8191 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.5221 - accuracy: 0.3813 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1844s 11s/step - loss: 2.5221 - accuracy: 0.3813 - val_loss: 0.9738 - val_accuracy: 0.8298 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.4664 - accuracy: 0.3948 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1796s 11s/step - loss: 2.4664 - accuracy: 0.3948 - val_loss: 0.9602 - val_accuracy: 0.8355 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.4038 - accuracy: 0.4034INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1815s 11s/step - loss: 2.4038 - accuracy: 0.4034 - val_loss: 0.9096 - val_accuracy: 0.8378 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.3530 - accuracy: 0.4178 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1816s 11s/step - loss: 2.3530 - accuracy: 0.4178 - val_loss: 0.8648 - val_accuracy: 0.8420 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.3133 - accuracy: 0.4226 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1807s 11s/step - loss: 2.3133 - accuracy: 0.4226 - val_loss: 0.8481 - val_accuracy: 0.8427 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.2529 - accuracy: 0.4351 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1822s 11s/step - loss: 2.2529 - accuracy: 0.4351 - val_loss: 0.8053 - val_accuracy: 0.8439 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.2188 - accuracy: 0.4461 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1829s 11s/step - loss: 2.2188 - accuracy: 0.4461 - val_loss: 0.7852 - val_accuracy: 0.8519 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.1781 - accuracy: 0.4508 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1816s 11s/step - loss: 2.1781 - accuracy: 0.4508 - val_loss: 0.7469 - val_accuracy: 0.8519 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.1359 - accuracy: 0.4608 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1841s 11s/step - loss: 2.1359 - accuracy: 0.4608 - val_loss: 0.7374 - val_accuracy: 0.8561 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.0803 - accuracy: 0.4712 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1813s 11s/step - loss: 2.0803 - accuracy: 0.4712 - val_loss: 0.7263 - val_accuracy: 0.8591 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.0519 - accuracy: 0.4747 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1831s 11s/step - loss: 2.0519 - accuracy: 0.4747 - val_loss: 0.6882 - val_accuracy: 0.8587 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.0277 - accuracy: 0.4853 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1828s 11s/step - loss: 2.0277 - accuracy: 0.4853 - val_loss: 0.6762 - val_accuracy: 0.8641 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.9874 - accuracy: 0.4905INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1800s 11s/step - loss: 1.9874 - accuracy: 0.4905 - val_loss: 0.6481 - val_accuracy: 0.8686 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.9574 - accuracy: 0.4949 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1818s 11s/step - loss: 1.9574 - accuracy: 0.4949 - val_loss: 0.6440 - val_accuracy: 0.8701 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.9172 - accuracy: 0.5039INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1820s 11s/step - loss: 1.9172 - accuracy: 0.5039 - val_loss: 0.6239 - val_accuracy: 0.8686 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.8989 - accuracy: 0.5069 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1870s 11s/step - loss: 1.8989 - accuracy: 0.5069 - val_loss: 0.6079 - val_accuracy: 0.8736 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.8723 - accuracy: 0.5123 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1844s 11s/step - loss: 1.8723 - accuracy: 0.5123 - val_loss: 0.6015 - val_accuracy: 0.8751 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.8373 - accuracy: 0.5248 INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 1828s 11s/step - loss: 1.8373 - accuracy: 0.5248 - val_loss: 0.5905 - val_accuracy: 0.8766 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "154/166 [==========================>...] - ETA: 2:01 - loss: 1.8015 - accuracy: 0.5311"
     ]
    }
   ],
   "source": [
    "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "    input_shape=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH, RAW_IMAGE_CHANNELS),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "#checkpoint_path = 'birds_classification_model_checkpoint'\n",
    "#checkpoint_path = 'birds_checkpoint_256'\n",
    "checkpoint_path = 'birds_checkpoint'\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",\n",
    "    patience = 5,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dropout(0.45)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.45)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(525, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "train_history = model.fit(\n",
    "    dataset_train,\n",
    "    steps_per_epoch=len(dataset_train),\n",
    "    validation_data=dataset_valid,\n",
    "    validation_steps=len(dataset_valid),\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        checkpoint_callback,\n",
    "        reduce_lr\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a825958-0e97-4942-82b1-79c61211190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PHILIPPINE EAGLE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "checkpoint_path = 'birds_checkpoint'\n",
    "model_1 = tf.keras.models.load_model(checkpoint_path)\n",
    "dataset_valid.class_names[np.argmax(model_1.predict(np.array([imread('data/test/PHILIPPINE EAGLE/1.jpg')])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c926444a-7e1b-4a96-bc78-531fa1d3eeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 17:21:15.470191: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-23 17:21:15.739765: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-23 17:21:15.995590: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-23 17:21:16.307256: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-23 17:21:16.488836: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 149s 13s/step - loss: 0.5905 - accuracy: 0.8766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5904751420021057, 0.8766184449195862]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c9e15d-8dea-458a-8233-e88ede224e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2626, (2626, 525))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04fef992-8d2a-4bc9-9d81-da657490821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 123s 11s/step\n",
      "0.0022425319455022428\n",
      "0.002284843869002285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = model_1.predict(dataset_valid)\n",
    "\n",
    "#y = np.argmax([l for _, ls in dataset_valid for l in ls], axis=1)\n",
    "#y_pred = np.argmax(predictions, axis=1)\n",
    "y = [l for _, ls in dataset_valid for l in ls]\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(f1_score(y, y_pred, average='weighted'))\n",
    "print(accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e7577b-2245-4e06-99ed-32a2244882f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2626, 525)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a052623-a9b3-4b4c-83c8-7735807d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y), len(y_pred))\n",
    "y, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee40421d-94c3-4e2d-a285-355d62cce446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.functional.Functional object at 0x7f330c248850>\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PHILIPPINE EAGLE'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "\n",
    "def F1_score(y_true, y_pred):\n",
    "    precision.update_state(y_true, y_pred)\n",
    "    recall.update_state(y_true, y_pred)\n",
    "    precision_result = precision.result()\n",
    "    recall_result = recall.result()\n",
    "    return 2 * ((precision_result * recall_result) / (precision_result + recall_result + 1e-6))\n",
    "\n",
    "tf.keras.utils.get_custom_objects()['F1_score'] = F1_score\n",
    "\n",
    "model_2 = tf.keras.models.load_model('data/EfficientNetB0-525-(224 X 224)- 98.97.h5', custom_objects={'F1_score':'F1_score'})\n",
    "#model_2 = tf.keras.models.load_model('data/EfficientNetB0-525-(224 X 224)- 98.97.h5')\n",
    "model_2.trainable = False\n",
    "print(model_2)\n",
    "dataset_valid.class_names[np.argmax(model_2.predict(np.array([imread('data/test/PHILIPPINE EAGLE/1.jpg')])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b280ebcd-f44f-48d6-8099-356e634788e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 83s 7s/step - loss: 0.3303 - accuracy: 0.9794 - F1_score: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33025839924812317, 0.9794363975524902, 0.9775663614273071]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da00a9-8753-4ea4-8de9-521f5db81f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(dataset_train.class_names, dataset_valid.class_names):\n",
    "    if i != j:\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31218a00-3d3d-4290-ac7f-17ea00de7337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13125 files belonging to 525 classes.\n",
      "Found 2626 files belonging to 525 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_mod_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_MOD_DIR,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH),\n",
    "    crop_to_aspect_ratio=True,\n",
    "    #seed=1  \n",
    ")\n",
    "dataset_valid = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR, 'valid'),\n",
    "    #label_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH),\n",
    "    crop_to_aspect_ratio=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "345c1445-35f8-43d8-aaca-87f125eecb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 03s]\n",
      "\n",
      "Best val_accuracy So Far: None\n",
      "Total elapsed time: 00h 00m 09s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |2                 |optim_int\n",
      "0.001             |0.0001            |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 235, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n",
      "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Model.fit() got multiple values for argument 'epochs'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 67, in error_handler\n    filtered_tb = _process_traceback_frames(e.__traceback__)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: Model.fit() got multiple values for argument 'epochs'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 71\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     63\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mHyperband(model_builder,\n\u001b[1;32m     64\u001b[0m      objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     65\u001b[0m      max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m      project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintro_to_kt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 71\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_mod_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:231\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:335\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[1;32m    330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# Display needs the updated trial scored by the Oracle.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display\u001b[38;5;241m.\u001b[39mon_trial_end(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:107\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    106\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[0;32m--> 107\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[1;32m    109\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:429\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:386\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/jmlazaro/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 67, in error_handler\n    filtered_tb = _process_traceback_frames(e.__traceback__)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: Model.fit() got multiple values for argument 'epochs'\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def model_builder(hp):\n",
    "\n",
    "    optim_dict = {1: tf.keras.optimizers.Adam, 2: tf.keras.optimizers.AdamW}\n",
    "    optim_str_dict = {1: 'adam', 2: 'adamw'}\n",
    "    optim_int = hp.Choice('optim_int', values=[1, 2])\n",
    "    optim = optim_dict[optim_int]\n",
    "    init_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    params = {'optim': optim_str_dict[optim_int], 'init_lr': init_lr}\n",
    "\n",
    "    checkpoint_path = os.path.join('checkpoints', '_'.join([f'{k}-{v}' for k, v in params.items()]))\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",\n",
    "        patience = 5,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "    pretrained_model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "        input_shape=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH, RAW_IMAGE_CHANNELS),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='max'\n",
    "    )\n",
    "    pretrained_model.trainable = False\n",
    "    \n",
    "    augment = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),\n",
    "    ])\n",
    "    \n",
    "    inputs = pretrained_model.input\n",
    "    x = augment(inputs)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "    x = tf.keras.layers.Dropout(0.45)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.45)(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(525, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optim(init_lr),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "     objective='val_accuracy',\n",
    "     max_epochs=10,\n",
    "     factor=3,\n",
    "     directory='my_dir',\n",
    "     project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "tuner.search(*dataset_mod_train, epochs=5, validation_data=dataset_valid)\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219fb39-b587-4b82-9bbe-4b411eaa2514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
